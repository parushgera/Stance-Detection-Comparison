{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "wMrwqRLs91Vf"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('punkt')\n",
    "from nltk.util import ngrams\n",
    "#from google.colab import drive\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy import sparse\n",
    "import os\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Data\n",
    "df = pd.read_csv('train.txt', sep='\\t')\n",
    "df1 = pd.read_csv('test.txt', sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "guwz2mom9-RN",
    "outputId": "d90bc4e9-cc1c-43ce-d5f6-a79ac5066271"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of train data is 1072\n",
      "The length of test data is 468\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "#Use below lines only when training different classifiers for different targerts and testing on their corrosponding data.\n",
    "t = ['Are E-Cigarettes safe?','Does MMR Vaccine lead to autism in children?',\n",
    "     'Does Sunlight exposure lead to skin cancer?','Does Vitamin C prevent common cold?',\n",
    "     'Should women take HRT post-menopause?']\n",
    "    \n",
    "\n",
    "\n",
    "print(\"The length of train data is {}\".format(len(df)))\n",
    "print(\"The length of test data is {}\".format(len(df1)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = 'tfidf'   # set 'count' or 'tfidf'\n",
    "analyzer = 'both'  # set 'word' or 'both' ( word and char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cu37tw9Vmm3p",
    "outputId": "497cfeae-f6d3-4588-b465-80ece0117023"
   },
   "outputs": [],
   "source": [
    "if vectorizer == 'count':\n",
    "    if analyzer == 'word':\n",
    "        vectorizer = CountVectorizer(analyzer='word',ngram_range=(1,1))\n",
    "    else:\n",
    "        vectorizer = CountVectorizer(analyzer='word',ngram_range=(1,3))\n",
    "        char_vectorizer = CountVectorizer(analyzer='char',ngram_range=(2,5))\n",
    "else:\n",
    "    if analyzer == 'word':\n",
    "        vectorizer = TfidfVectorizer(analyzer='word',ngram_range=(1,1))\n",
    "    else:\n",
    "        vectorizer = TfidfVectorizer(analyzer='word',ngram_range=(1,3))\n",
    "        char_vectorizer = TfidfVectorizer(analyzer='char',ngram_range=(2,5))\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L5QKhyyn3GW3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "pqbMqivk-EBF"
   },
   "outputs": [],
   "source": [
    "#List of FAVOR Tweets\n",
    "def get_training_data_and_labels(df):\n",
    "    df_train_favor = df.loc[df['Stance'] == 'FAVOR']\n",
    "    df_train_favor = df_train_favor.reset_index(drop=True)\n",
    "    train_favor_tweets = df_train_favor['Tweet'].tolist()\n",
    "    \n",
    "    # List of AGAINST Tweets\n",
    "    df_train_against = df.loc[df['Stance'] == 'AGAINST']\n",
    "    df_train_against = df_train_against.reset_index(drop=True)\n",
    "    train_against_tweets = df_train_against['Tweet'].tolist()\n",
    "    \n",
    "    #Favor + Against Tweets and Labels\n",
    "    train_corpus = train_favor_tweets + train_against_tweets\n",
    "    train_labels = np.append(np.ones((len(train_favor_tweets))) , np.zeros((len(train_against_tweets))))\n",
    "    \n",
    "    \n",
    "    if analyzer == 'word':\n",
    "        ngram_vectorized_data = vectorizer.fit_transform(train_corpus)\n",
    "        \n",
    "        return ngram_vectorized_data, train_labels\n",
    "    else:\n",
    "        ngram_vectorized_data = vectorizer.fit_transform(train_corpus)\n",
    "        char_vectorized_data = char_vectorizer.fit_transform(train_corpus)\n",
    "        l = np.hstack((ngram_vectorized_data.toarray(), char_vectorized_data.toarray()))\n",
    "        train_vectorized_data = sparse.csr_matrix(l)\n",
    "        \n",
    "        return train_vectorized_data, train_labels \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H2QL4bjHgloM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "rKNZ6AA4G9Tv"
   },
   "outputs": [],
   "source": [
    "#preparing test_data\n",
    "def get_test_data_and_labels(df1):\n",
    "    df_test_favor = df1.loc[df1['Stance']=='FAVOR']\n",
    "    df_test_favor = df_test_favor.reset_index(drop=True)\n",
    "    test_favor_tweets = df_test_favor['Tweet'].tolist()\n",
    "    print(len(test_favor_tweets))\n",
    "    \n",
    "    \n",
    "    df_test_against = df1.loc[df1['Stance'] == 'AGAINST']\n",
    "    df_test_against = df_test_against.reset_index(drop=True)\n",
    "    test_against_tweets = df_test_against['Tweet'].tolist()\n",
    "    print(len(test_against_tweets))\n",
    "    \n",
    "    \n",
    "    test_corpus = test_favor_tweets + test_against_tweets\n",
    "    test_labels = np.append(np.ones((len(test_favor_tweets))) , np.zeros((len(test_against_tweets))))\n",
    "    \n",
    "    if analyzer == 'word':\n",
    "        test_ngram_vectorized_data = vectorizer.transform(test_corpus)\n",
    "        \n",
    "        return test_ngram_vectorized_data, test_labels\n",
    "    else:\n",
    "        test_ngram_vectorized_data = vectorizer.transform(test_corpus)\n",
    "        test_char_vectorized_data = char_vectorizer.transform(test_corpus)\n",
    "        l2 = np.hstack((test_ngram_vectorized_data.toarray(), test_char_vectorized_data.toarray()))\n",
    "        test_vectorized_data = sparse.csr_matrix(l2)\n",
    "        \n",
    "        return test_vectorized_data,test_labels\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lBQR_GZS-Zwd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QgrH2FsLNu8B",
    "outputId": "577a1218-22f0-4183-b362-09a027f2fe2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138\n",
      "163\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train =  get_training_data_and_labels(df)\n",
    "X_test, y_test = get_test_data_and_labels(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "# dummy_clf.fit(X_train, y_train)\n",
    "# y_true, y_pred = y_test, dummy_clf.predict(X_test)\n",
    "# # dummy_clf.score(X_test,y_test)\n",
    "# print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tR4ULhqpQR_h",
    "outputId": "5866db2f-b8f4-46a1-a353-8a1ac3a616db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/export/apps/anaconda3-gpu/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1, 'kernel': 'linear'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.285 (+/-0.003) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.285 (+/-0.003) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.285 (+/-0.003) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.285 (+/-0.003) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.420 (+/-0.393) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.285 (+/-0.003) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.651 (+/-0.227) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.419 (+/-0.393) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.653 (+/-0.226) for {'C': 1, 'kernel': 'linear'}\n",
      "0.651 (+/-0.227) for {'C': 10, 'kernel': 'linear'}\n",
      "0.651 (+/-0.227) for {'C': 100, 'kernel': 'linear'}\n",
      "0.651 (+/-0.227) for {'C': 1000, 'kernel': 'linear'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.82      0.78       163\n",
      "         1.0       0.75      0.66      0.70       138\n",
      "\n",
      "    accuracy                           0.74       301\n",
      "   macro avg       0.75      0.74      0.74       301\n",
      "weighted avg       0.74      0.74      0.74       301\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1, 'kernel': 'linear'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.500 (+/-0.000) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.500 (+/-0.000) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.500 (+/-0.000) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.500 (+/-0.000) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.498 (+/-0.034) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.500 (+/-0.000) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.623 (+/-0.223) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.498 (+/-0.037) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.624 (+/-0.223) for {'C': 1, 'kernel': 'linear'}\n",
      "0.623 (+/-0.223) for {'C': 10, 'kernel': 'linear'}\n",
      "0.623 (+/-0.223) for {'C': 100, 'kernel': 'linear'}\n",
      "0.623 (+/-0.223) for {'C': 1000, 'kernel': 'linear'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.82      0.78       163\n",
      "         1.0       0.75      0.66      0.70       138\n",
      "\n",
      "    accuracy                           0.74       301\n",
      "   macro avg       0.75      0.74      0.74       301\n",
      "weighted avg       0.74      0.74      0.74       301\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100, 1000]}, {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "\n",
    "for score in scores:\n",
    "    \n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(\n",
    "        SVC(), tuned_parameters, scoring='%s_macro' % score\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "iPmjri5VbvZP"
   },
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "import pickle\n",
    "filename = 'svm_tfidf_both_mpchi.sav'\n",
    "pickle.dump(clf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ryWZpF-zxohF",
    "outputId": "54ddc458-facf-4811-cf86-7aa438113765"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report for                precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.82      0.78       163\n",
      "         1.0       0.75      0.66      0.70       138\n",
      "\n",
      "    accuracy                           0.74       301\n",
      "   macro avg       0.75      0.74      0.74       301\n",
      "weighted avg       0.74      0.74      0.74       301\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# df_all = pd.read_csv('test.csv')\n",
    "# X_test, y_test = get_test_data_and_labels(df_all)\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "print('Report for ', classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DCebQWZuqO3U",
    "outputId": "b36a171a-b1b7-4737-e616-887c412aa8fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "47\n",
      "Report for  Are E-Cigarettes safe?               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.81      0.77        47\n",
      "         1.0       0.68      0.58      0.62        33\n",
      "\n",
      "    accuracy                           0.71        80\n",
      "   macro avg       0.70      0.69      0.70        80\n",
      "weighted avg       0.71      0.71      0.71        80\n",
      "\n",
      "24\n",
      "33\n",
      "Report for  Does MMR Vaccine lead to autism in children?               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.94      0.85        33\n",
      "         1.0       0.88      0.62      0.73        24\n",
      "\n",
      "    accuracy                           0.81        57\n",
      "   macro avg       0.83      0.78      0.79        57\n",
      "weighted avg       0.82      0.81      0.80        57\n",
      "\n",
      "35\n",
      "26\n",
      "Report for  Does Sunlight exposure lead to skin cancer?               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.69      0.65        26\n",
      "         1.0       0.75      0.69      0.72        35\n",
      "\n",
      "    accuracy                           0.69        61\n",
      "   macro avg       0.69      0.69      0.69        61\n",
      "weighted avg       0.69      0.69      0.69        61\n",
      "\n",
      "37\n",
      "16\n",
      "Report for  Does Vitamin C prevent common cold?               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.47      0.44      0.45        16\n",
      "         1.0       0.76      0.78      0.77        37\n",
      "\n",
      "    accuracy                           0.68        53\n",
      "   macro avg       0.61      0.61      0.61        53\n",
      "weighted avg       0.67      0.68      0.68        53\n",
      "\n",
      "9\n",
      "41\n",
      "Report for  Should women take HRT post-menopause?               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.95      0.92        41\n",
      "         1.0       0.67      0.44      0.53         9\n",
      "\n",
      "    accuracy                           0.86        50\n",
      "   macro avg       0.78      0.70      0.73        50\n",
      "weighted avg       0.85      0.86      0.85        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  t = ['Are E-Cigarettes safe?',\n",
    "#        'Does MMR Vaccine lead to autism in children?',\n",
    "#        'Does Sunlight exposure lead to skin cancer?',\n",
    "#        'Does Vitamin C prevent common cold?',\n",
    "#        'Should women take HRT post-menopause?']\n",
    "\n",
    "# for target in t:\n",
    "#     df_test = df1[(df1[\"Target\"]== target) ]\n",
    "#     X_test, y_test = get_test_data_and_labels(df_test)\n",
    "#     y_true, y_pred = y_test, clf.predict(X_test)\n",
    "#     print('Report for ',target, classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tkt-iBNjQ2WA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "id": "VhFyOPDNaKFW"
   },
   "outputs": [],
   "source": [
    "#print(len(test_count_vectorizer.get_feature_names()))\n",
    "\n",
    "#test_indexed_data = hstack((np.array(range(0,test_vectorized_data.shape[0]))[:,None], test_vectorized_data)) #adding a column for index and stacking data 3614 X 100285\n",
    "#test_indexed_data.shape\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(indexed_data, labels, test_size=0.4, random_state=0, shuffle = True)\n",
    "#X_train,, y_train = indexed_data , labels\n",
    "#data_train_index = X_train[:,0]\n",
    "#print(X_test.shape)\n",
    "#print(data_train_index)\n",
    "#X_train = X_train[:,1:]\n",
    "#data_test_index = X_test[:,0]\n",
    "#print(data_test_index)\n",
    "#X_test = X_test[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MrqI0RAdxeSs"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fKwr73fHxe_G"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Count_Stance.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
